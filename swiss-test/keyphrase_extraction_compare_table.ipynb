{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import accuracy_score\n",
    "from swisscom import launch\n",
    "import en_core_web_sm as english\n",
    "from tqdm.notebook import tqdm\n",
    "from string import punctuation\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")\n",
    "\n",
    "\n",
    "data = pd.read_csv('./dataset.csv', dtype=str)\n",
    "nlp = english.load()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [],
   "source": [
    "X = data['text']\n",
    "y = data['loc'].astype(str)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [],
   "source": [
    "BACKGROUND_TAGS = [\"valley\", \"hill\", \"mountain\", \"city\", \"sea\", \"bay\", \"beach\", \"forest\", \"field\", \"road\", \"urban\", \"rural\", \"highway\", \"modern building\", \"historical building\", \"ancient ruins\", \"tropics\", \"desert\", \"swamp\", \"lake\", \"outskirts\", \"luxury\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [],
   "source": [
    "def extract_keywords(nlp, sequence, special_tags : list = None):\n",
    "    result = []\n",
    "\n",
    "    pos_tag = ['PROPN','NOUN','ADJ']\n",
    "\n",
    "    doc = nlp(sequence.lower())\n",
    "\n",
    "    if special_tags:\n",
    "        tags = [tag.lower() for tag in special_tags]\n",
    "        for token in doc:\n",
    "            if token.text in tags:\n",
    "                result.append(token.text)\n",
    "\n",
    "    for chunk in doc.noun_chunks:\n",
    "        final_chunk = \"\"\n",
    "        for token in chunk:\n",
    "            if token.pos_ in pos_tag:\n",
    "                final_chunk =  final_chunk + token.text + \" \"\n",
    "        if final_chunk:\n",
    "            result.append(final_chunk.strip())\n",
    "\n",
    "\n",
    "    for token in doc:\n",
    "        if token.text in nlp.Defaults.stop_words or token.text in punctuation:\n",
    "            continue\n",
    "        if token.pos_ in pos_tag:\n",
    "            result.append(token.text)\n",
    "\n",
    "    return list(set(result))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [],
   "source": [
    "def predict_spacy(nlp, X):\n",
    "    doc = list(map(lambda text: extract_keywords(nlp, text, BACKGROUND_TAGS), X))\n",
    "    return doc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [],
   "source": [
    "class KeyPhraseExtractionModel(BaseEstimator):\n",
    "    def __init__(self, embedding_model='roberta-large-nli-stsb-mean-tokens', beta=0.8, alias_threshold=0.7, n=1):\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.beta = beta\n",
    "        self.n = n\n",
    "        self.alias_threshold = alias_threshold\n",
    "        self.embedding_distributor = launch.load_local_embedding_distributor(embedding_model)\n",
    "        self.pos_tagger = launch.load_local_corenlp_pos_tagger()\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        return list(map(lambda text: launch.extract_keyphrases(self.embedding_distributor, self.pos_tagger, text, self.n, 'en', self.beta, self.alias_threshold)[0][0], X))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [],
   "source": [
    "models = [\n",
    "    'sent2vec',\n",
    "    'roberta-large-nli-stsb-mean-tokens',\n",
    "    'roberta-base-nli-stsb-mean-tokens',\n",
    "    'distilbert-base-nli-stsb-mean-tokens',\n",
    "    'paraphrase-distilroberta-base-v1',\n",
    "    'distilroberta-base-msmarco-v2',\n",
    "    'LaBSE',\n",
    "]\n",
    "\n",
    "model_map_name = {\n",
    "    'sent2vec': 'EmbedRank with sent2vec',\n",
    "    'roberta-large-nli-stsb-mean-tokens': 'RoBERTa Large ',\n",
    "    'roberta-base-nli-stsb-mean-tokens': 'RoBERTa Base',\n",
    "    'distilbert-base-nli-stsb-mean-tokens': 'DistilBERT Base',\n",
    "    'paraphrase-distilroberta-base-v1': 'DistilBERT Paraphrase v1',\n",
    "    'distilroberta-base-msmarco-v2': 'DistilRoBERTa Base msmarco',\n",
    "    'LaBSE': 'LaBSE',\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [],
   "source": [
    "model_results = {}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [],
   "source": [
    "def spacy_collect(y_true, y_pred):\n",
    "    result = []\n",
    "    for y_t, y_p in list(zip(y_true, y_pred)):\n",
    "        if y_t in y_p:\n",
    "            result.append(y_t)\n",
    "        else:\n",
    "            result.append(y_p[0])\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/7 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "56722318a4a64163814d9aced240fccd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spacy_score = accuracy_score(y_true=y, y_pred=spacy_collect(y, predict_spacy(nlp, X)))\n",
    "model_results['Spacy BERT'] = '{}%'.format(int(100. * spacy_score))\n",
    "\n",
    "for embedding_model in tqdm(list(models)):\n",
    "    model = KeyPhraseExtractionModel(embedding_model)\n",
    "    model.fit(X, y)\n",
    "    score = accuracy_score(y_true=y, y_pred=model.predict(X))\n",
    "    model_results[model_map_name[embedding_model]] = '{}%'.format(int(100. * score))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [
    {
     "data": {
      "text/plain": "<pandas.io.formats.style.Styler at 0x7f8240e6c970>",
      "text/html": "<style  type=\"text/css\" >\n</style><table id=\"T_0e0eb_\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Model</th>        <th class=\"col_heading level0 col1\" >Accuracy</th>    </tr></thead><tbody>\n                <tr>\n                                <td id=\"T_0e0eb_row0_col0\" class=\"data row0 col0\" >Spacy BERT</td>\n                        <td id=\"T_0e0eb_row0_col1\" class=\"data row0 col1\" >64%</td>\n            </tr>\n            <tr>\n                                <td id=\"T_0e0eb_row1_col0\" class=\"data row1 col0\" >EmbedRank with sent2vec</td>\n                        <td id=\"T_0e0eb_row1_col1\" class=\"data row1 col1\" >78%</td>\n            </tr>\n            <tr>\n                                <td id=\"T_0e0eb_row2_col0\" class=\"data row2 col0\" >RoBERTa Large </td>\n                        <td id=\"T_0e0eb_row2_col1\" class=\"data row2 col1\" >47%</td>\n            </tr>\n            <tr>\n                                <td id=\"T_0e0eb_row3_col0\" class=\"data row3 col0\" >RoBERTa Base</td>\n                        <td id=\"T_0e0eb_row3_col1\" class=\"data row3 col1\" >44%</td>\n            </tr>\n            <tr>\n                                <td id=\"T_0e0eb_row4_col0\" class=\"data row4 col0\" >DistilBERT Base</td>\n                        <td id=\"T_0e0eb_row4_col1\" class=\"data row4 col1\" >46%</td>\n            </tr>\n            <tr>\n                                <td id=\"T_0e0eb_row5_col0\" class=\"data row5 col0\" >DistilBERT Paraphrase v1</td>\n                        <td id=\"T_0e0eb_row5_col1\" class=\"data row5 col1\" >60%</td>\n            </tr>\n            <tr>\n                                <td id=\"T_0e0eb_row6_col0\" class=\"data row6 col0\" >DistilRoBERTa Base msmarco</td>\n                        <td id=\"T_0e0eb_row6_col1\" class=\"data row6 col1\" >64%</td>\n            </tr>\n            <tr>\n                                <td id=\"T_0e0eb_row7_col0\" class=\"data row7 col0\" >LaBSE</td>\n                        <td id=\"T_0e0eb_row7_col1\" class=\"data row7 col1\" >57%</td>\n            </tr>\n    </tbody></table>"
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    'Model': model_results.keys(),\n",
    "    'Accuracy': model_results.values()\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data, columns=['Model', 'Accuracy'])\n",
    "df.style.hide_index()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}